<!doctype html><html lang="en"><head><meta charset="UTF-8"><title>Ryan Groves</title><link rel="preconnect" href="https://fonts.gstatic.com"><link href="https://fonts.googleapis.com/css2?family=Archivo+Black&family=Cabin+Sketch:wght@400;700&family=Raleway:wght@400;700&display=swap" rel="stylesheet"><link rel="shortcut icon" href="/img/favicons/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/img/favicons/favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/favicons/favicon-32x32.png"><link rel="manifest" href="/img/favicons/manifest.json"><meta name="mobile-web-app-capable" content="yes"><meta name="theme-color" content="#fff"><meta name="application-name" content="Site"><link rel="apple-touch-icon" sizes="57x57" href="/img/favicons/apple-touch-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/img/favicons/apple-touch-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/img/favicons/apple-touch-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicons/apple-touch-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/img/favicons/apple-touch-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/img/favicons/apple-touch-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/img/favicons/apple-touch-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/img/favicons/apple-touch-icon-152x152.png"><link rel="apple-touch-icon" sizes="167x167" href="/img/favicons/apple-touch-icon-167x167.png"><link rel="apple-touch-icon" sizes="180x180" href="/img/favicons/apple-touch-icon-180x180.png"><link rel="apple-touch-icon" sizes="1024x1024" href="/img/favicons/apple-touch-icon-1024x1024.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="apple-mobile-web-app-title" content="Site"><meta name="viewport" content="width=device-width,initial-scale=1"><link href="./style.5020a066b3356d9e52b8.css" rel="stylesheet"><link href="./style.5422933f5660929fedd9.css" rel="stylesheet"></head><body><header><div class="container"><div class="row"><div class="col-12 col-md-10 d-flex align-items-center justify-content-center justify-content-md-start mb-4 mb-md-0"><a href="/" class="d-flex"><img src="img/back-arrow.87fd4503241ef5102c19d833a198f9b5.svg" alt="Back button" class="back-btn"><p class="title">Ryan Groves</p></a><span class="header-delimiter">/</span><p class="page-name">Speaking</p></div><div class="col-12 col-md-2 text-center text-md-right my-auto"><p><a class="home-btn" href="/">Home</a></p></div></div></div></header><section id="mit-talk" class="mit-talk"><div class="container"><div class="row mb-5"><div class="col-6 col-lg-4"><img class="img-fluid" src="img/mit.1ce57d168c877c438dc2f3074f1d156a.png" alt="mit-logo"></div><div class="col-6 col-lg-4 d-flex justify-content-center"><img class="img-fluid" src="img/berklee.7082dfe4e36e1135c7e9dbfd606c6ea1.png" alt="berklee-logo"></div><div class="col-12 col-lg-4 d-flex justify-content-center justify-content-lg-end mt-5 mt-lg-0"><img class="img-fluid" src="img/harvard.8efa59bb0198a5c0390edb6b4680903c.png" alt="harvard-logo"></div></div><div class="row"><div class="col-12 col-lg-6 order-2 order-lg-1"><div class="mt-5 mt-lg-0"><div class="video-rel mb-2"><div class="iframe-container"><iframe src="https://drive.google.com/file/d/10jeliMc4vHArN-v2121fgUEHUI4ectxG/preview"></iframe></div><a data-toggle="video-modal" data-target="#video-modal" data-video="https://drive.google.com/file/d/10jeliMc4vHArN-v2121fgUEHUI4ectxG/preview"></a></div><p class="text-center text-lg-left">Full class information can be found <a class="blue-link" href="http://infinitealbum.io/MITLecture">here.</a></p></div></div><div class="col-12 col-lg-6 order-1 order-lg-2 my-auto"><p class="text-center text-lg-left title-text text-bold text-capitalize">Guest Lecture - An Emergent Art Movement: <span>AI & Music in XR</span></p><p>For this joint VR class on <span class="text-bold">Building Immersive Experiences</span>, with students from MIT, Berklee College of Music and Harvard, each student was given a VR headset. Ryan Groves coordinated the creation of a custom VR world where the students met for the lecture, and speakers Ryan Groves, Roman Rappak and Dan Franke discussed their work in AI music generation for XR, live music in XR, and VR animation for music experiences.</p></div></div></div></section><div class="section-divider"></div><section class="stanford" id="stanford"><div class="container"><div class="row"><div class="col-12 col-lg-6"><div class="mb-5 mb-lg-0"><div class="d-flex justify-content-center"><img class="stanford__logo img-fluid" src="img/standford.a85689808d591ef2bfb03505b974f6e3.png" alt="stanford-logo"></div><p class="text-center text-lg-left title-text text-bold text-capitalize">Keynote Lecture - Building <span>Artificially Intelligent</span> Musical Composers</p></div></div><div class="col-12 col-lg-6 d-flex justify-content-center justify-content-lg-start video-rel mb-2 md-md-0"><div class="iframe-container"><iframe src="https://www.youtube.com/embed/e0ANfZfBXtM" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div><a data-toggle="video-modal" data-target="#video-modal" data-video="https://www.youtube.com/embed/e0ANfZfBXtM"></a></div></div><div class="row"><div class="col-12 col-lg-6 d-flex justify-content-center justify-content-lg-start mb-5 mb-lg-0"><img class="stanford-talk img-fluid" src="img/stanford_talk.7e5f0b4e0b0570e5d3b3722046f5ad8e.png" alt="img-fluid"></div><div class="col-12 col-lg-6 d-flex align-items-center"><div><p class="mb-4">In the Keynote Lecture for Stanford Music Technology group, CCRMA, Ryan highlighted the different musical components of the vast topic of automatic musical composition.</p><p>Given his background of computational music theory, he emphasized the importance of building and validating machine-learning models that can perform particular musical tasks, and leveraging those to create artificially intelligent compositional agents that can perform the entire music creation process.</p></div></div></div></div></section><div class="section-divider"></div><section class="tech-crunch" id="tech-crunch"><div class="container"><div class="row"><div class="col-12 col-lg-6 d-flex flex-column justify-content-center"><div class="mb-5 mb-lg-0"><div class="d-flex justify-content-center"><img class="tech-crunch__logo img-fluid" src="img/techcrunch.74c9e9724f292d0c81515facc5d64e7b.png" alt="tech-crunch-logo"></div><p class="text-center text-lg-left title-text text-bold text-capitalize">Startup Battlefield Finalist - <span>Arcona</span></p></div></div><div class="col-12 col-lg-6 d-flex justify-content-center justify-content-lg-end"><div class="ryan-full mb-5 mb-lg-0"><p class="d-none d-lg-block text-bold">Ryan Groves</p><img class="img-fluid" src="img/ryan.2f8ef51958d4e0eaaeadb2b506762c04.png" alt="ryan-groves"></div></div></div><div class="row"><div class="col-12 col-lg-6 d-flex justify-content-center justify-content-lg-start video-rel"><div class="iframe-container"><iframe src="https://www.youtube.com/embed/zbmM5JatoQM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div><a data-toggle="video-modal" data-target="#video-modal" data-video="https://www.youtube.com/embed/zbmM5JatoQM"></a></div><div class="col-12 col-lg-6 d-flex align-items-center"><div><p class="tech-crunch__description">Arcona uses machine learning to compose adaptive soundtracks in real time. Ryan Groves took the stage at TechCrunch Disrupt to pitch the application as a solution for rhythm games.</p></div></div></div></div></section><div class="section-divider"></div><section class="sxsw2020" id="sxsw2020"><div class="container"><div class="row"><div class="col-12 col-lg-6 d-flex flex-column justify-content-center"><div class="mb-5 mb-lg-0"><div class="d-flex justify-content-center justify-content-lg-start"><img class="sxsw2020__logo img-fluid" src="img/sxsw2020.5c0ddb6abf6c704e67f7ee77a6614e33.png" alt="sxsw-logo"></div><p class="title-text text-bold text-capitalize"><span>SXSW panel</span>: the future of live music, blended reality</p><p>Organized and moderated by Ryan Groves, XR provides a huge opportunity to reinvent the shared musical experience. Platforms have tried new approaches to live music–either by streaming concerts in VR or by creating VR-exclusive events. But most approaches either fail to replicate the experience of an in-person event or explicitly exclude a co-located audience. Certain groups, however, are creating new music experiences using a mix of VR, AR and live venues.</p><p>Our panel consists of experts at the intersection of Music and VR. Anne McKinnon is an XR consultant, advisor and writer, focused on immersive events. Eric Wagliardo founded &Pull and created Pharos AR, a collaboration with Childish Gambino. Roman Rappak is the lead creative of Miro Shot, an XR band/collective. Ryan Groves is a music technologist and founder of Arcona.ai.</p></div></div><div class="col-12 col-lg-6"><div class="sxsw2020__portraits-row d-flex justify-content-around"><div><img class="img-fluid" src="img/ryanface.1acc60a6b685c66991ebd6f73d7c344d.png" alt="ryan-groves"><p>Ryan Groves</p></div><div><img class="img-fluid" src="img/anne.e474a67d6b600769d9fc6f747a2f3faf.png" alt="anne-mckinnon"><p>Anne McKinnon</p></div></div><div class="sxsw2020__portraits-row d-flex justify-content-around"><div><img class="img-fluid" src="img/roman.296ac2af2fb91a9c994124bc528825ae.png" alt="roman-rappak"><p>Roman Rappak</p></div><div><img class="img-fluid" src="img/eric.4e5fb0a561afaa5cf5b412b28e880555.png" alt="eric-wagliardo"><p>Eric Wagliardo</p></div></div><iframe title="SXSW 2020 - The Future of Live Music: Blended Realities" width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https://api
                    .soundcloud.com/tracks/866165506&color=#ff5500&auto_play=false&hide_re
                    lated=false&show_comments=true&show_user=true&show_reposts=false&show_
                    teaser=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Luci
                    da Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/arcona-ai" title="Arcona AI" target="_blank" style="color: #cccccc; text-decoration: none;">Arcona A I</a> · <a href="https://soundcloud.com/arcona-ai/sxsw-2020-the-future-o
                    f-live-music-blended-realities" title="SXSW 2020 - The Future of Live Mu
                    sic: Blended Realities" target="_blank" style="color: #cccccc; text-decoration: none;">SXSW 2020 - The Future of Live Music: Blended Realities</a></div></div></div></div></section><div class="section-divider"></div><section class="sxsw2019-1" id="sxsw2019-1"><div class="container"><div class="row"><div class="col-12 col-lg-3 d-flex d-lg-block justify-content-between order-2 order-lg-1"><div class="sxsw2019-1__portrait"><img class="img-fluid" src="img/ryanface.1acc60a6b685c66991ebd6f73d7c344d.png" alt="ryan-groves"><p>Ryan Groves</p></div><div class="sxsw2019-1__portrait"><img class="img-fluid" src="img/byrke.4a477792898306ce55cb6dfc81ebc138.png" alt="byrke-lou"><p>Byrke Lou</p></div><div class="sxsw2019-1__portrait"><img class="img-fluid" src="img/pascal.5f6c36cd33fab992adb6b72dfceb5a76.png" alt="pascal-pilon"><p>Pascal Pilon</p></div></div><div class="col-12 col-lg-9 d-flex flex-column justify-content-center order-1 order-lg-2 mb-5 mb-lg-0"><div><div class="d-flex justify-content-center justify-content-lg-start"><img class="sxsw2020__logo img-fluid" src="img/sxsw.8d14c6ca7346d4a5cca288c2f5a8b314.png" alt="sxsw-logo"></div><p class="text-center text-lg-left title-text text-bold text-capitalize">The <span>Impact of AI</span> on Music Creation</p><p>Organized and moderated by Ryan Groves. Artificial Intelligence is advancing at an exceptional rate-continually redefining the set of activities that were previously only achievable by humans. Indeed, even the creative industries have been impacted. But the dialogue about AI for creative activities doesn’t have to be one of conflict and replacement.</p><p>Recently, music technologists are using AI to extend what humans can do musically - to foster collaboration, to create rapid musical prototypes, and to create new modes of music consumption. Two pioneers in this field are the companies Landr and Melodrive. Landr uses AI to automatically master musical tracks, but also enables users to collaborate, share and promote their music. Melodrive is creating an AI that composes - and re-composes - music, so that it can be truly adaptive.</p><audio controls><source src="http://audio.sxsw.com/2019/events/PP91834.mp3" type="audio/mpeg"></audio></div></div></div></div></section><div class="section-divider"></div><section class="sxsw2019-2" id="sxsw2019-2"><div class="container"><div class="row"><div class="col-12 col-lg-9 d-flex flex-column justify-content-center"><div><div class="sxsw2020__logo d-flex justify-content-center justify-content-lg-start"><img class="img-fluid" src="img/sxsw.8d14c6ca7346d4a5cca288c2f5a8b314.png" alt="sxsw-logo"></div><p class="text-center text-lg-left title-text text-bold text-capitalize">The Next Uncanny Valley: <span>Interaction in XR</span></p><p>Organized and moderated by Ryan Groves. Visual technologies have come a very long way in terms of being able to accurately simulate 3D environments and human appearance in controlled situations. The so-called “Uncanny Valley” has been centered around visual resemblance. With the rise of AI and the access to interactive tech, there is a new Uncanny Valley being created through human-like characters and interactions - where the focus is on narrative rather than visuals.</p><p>This creates an opportunity to redefine how people engage and interact with machines, and with each other. This new paradigm will not only require new tools, like storyboarding in VR (Galatea) and emotion-driven music (Melodrive), but also new approaches to promote introspective interactions (Where Thoughts Go), and new methodologies for the performance and direction of this new theatrical medium (Fiona Rene).</p><audio controls><source src="http://audio.sxsw.com/2019/events/PP91484.mp3" type="audio/mpeg"></audio><div class="d-flex justify-content-center justify-content-lg-start mb-5 mb-lg-0 video-rel"><div class="iframe-container"><iframe src="https://drive.google.com/file/d/1bq48rJphuhVUWEnIZgNFhH0JHPDpSj_a/preview" width="640" height="480"></iframe></div><a data-toggle="video-modal" data-target="#video-modal" data-video="https://drive.google.com/file/d/1bq48rJphuhVUWEnIZgNFhH0JHPDpSj_a/preview"></a></div></div></div><div class="col-12 col-lg-3 d-flex flex-row flex-lg-column justify-content-around justify-content-lg-center"><div><div class="sxsw2019-2__portrait"><img class="img-fluid" src="img/ryanface.1acc60a6b685c66991ebd6f73d7c344d.png" alt="ryan-groves"><p>Ryan Groves</p></div><div class="sxsw2019-2__portrait"><img class="img-fluid" src="img/fiona.c89df7346f28678cb17e7ac777cc2f9b.png" alt="fiona-rene"><p>Fiona Rene</p></div></div><div><div class="sxsw2019-2__portrait"><img class="img-fluid" src="img/lucas.98e28d786d276a4075395d962020e1db.png" alt="lucas-rizzotto"><p>Lucas Rizzotto</p></div><div class="sxsw2019-2__portrait sxsw2019-2__portrait-no-margin"><img class="img-fluid" src="img/jesse.e8b8671dc982976c4f463273d06ae483.png" alt="jesse-damiani"><p>Jesse Damiani</p></div></div></div></div></div></section><div class="section-divider"></div><section class="ismir-talk" id="ismir-talk"><div class="container"><div class="row"><div class="col-12 col-lg-6 order-2 order-lg-1"><div class="d-flex justify-content-center justify-content-lg-start"><img class="img-fluid mb-2" src="img/talk_img.f80596658927a6d9628350b0f2f7d13d.png" alt="ismir-talk"></div><p class="text-center text-lg-left">Won Best Paper overall, see <a class="blue-link" href="#">Awards</a> for more info.</p></div><div class="col-12 col-lg-6 oder-1 order-lg-2 mb-5 mb-lg-0"><div class="ismir-talk__logos d-flex flex-column flex-lg-row justify-content-around justify-content-lg-between"><div class="d-flex justify-content-center"><img class="img-fluid" src="img/ismir.766dc5aa8bfdfc5381b66e2fd3e848d9.png" alt="ismir-logo"></div><div class="d-flex justify-content-center"><img class="img-fluid" src="img/nyu.315998709658df554c33e822fd0abe6b.png" alt="nyu-logo"></div></div><p class="text-center text-lg-left title-text text-bold text-capitalize"><span>Highlighted</span> Talk</p><p>At the 2016 conference for the International Society for Music Information Retrieval, Ryan Groves presented his work on automatically reducing melodies using machine learning techniques borrowed from Natural Language Processing (NLP), titled: "Automatic Melodic Reduction Using a Supervised Probabilistic Context-Free Grammar".</p></div></div></div></section><div class="section-divider"></div><section class="additional-talks" id="additional-talks"><div class="container"><div class="row"><div class="col-12"><p class="text-center text-lg-left title-text text-bold text-capitalize">Additional <span>Talks/Lectures</span></p></div></div><div class="row"><div class="col-12 col-lg-4 mb-5 mb-lg-0 d-flex justify-content-center justify-content-lg-start"><img class="image-fluid" src="img/vrdays.5df461ea784f5a66d9bc7c79e3d2df4a.png" alt="vr-days-europe"></div><div class="col-12 col-lg-8 my-auto"><p class="text-center text-lg-left title-text text-capitalize"><span>Panel participant</span>, Music & VR, (2019)</p></div></div><div class="row"><div class="col-12 col-lg-4 mb-5 mb-lg-0 d-flex justify-content-center justify-content-lg-start"><img class="image-fluid" src="img/dafx.d16371e311959a7c8b91c683f1dec487.png" alt="dafx-2019"></div><div class="col-12 col-lg-8 my-auto"><p class="text-center text-lg-left title-text text-capitalize"><span>Guest Lecture</span>, Adaptive Music in Gaming (2017)</p></div></div><div class="row"><div class="col-12 col-lg-4 mb-5 mb-lg-0 d-flex justify-content-center justify-content-lg-start"><img class="image-fluid" src="img/data-science.94de9d79f039b8dbf000737b3d14dd27.png" alt="dafx-2019"></div><div class="col-12 col-lg-8 my-auto"><p class="text-center text-lg-left title-text text-capitalize"><span>Lectures</span>: Python for Machine Learning; Algorithms (2019-)</p></div></div><div class="row"><div class="col-12 col-lg-4 mb-5 mb-lg-0 d-flex justify-content-center justify-content-lg-start"><img class="image-fluid" src="img/wallifornia.c3c7cc733ccf9e7440d45a7809664250.png" alt="wallifornia"></div><div class="col-12 col-lg-8 my-auto"><p class="text-center text-lg-left title-text text-capitalize"><span>Invited Talk</span>, Building AI: A Systematic Approach to Music Data Problems</p></div></div><div class="row"><div class="col-12 col-lg-4 mb-5 mb-lg-0 d-flex justify-content-center justify-content-lg-start"><img class="image-fluid" src="img/pandora.7b334e18b639d1087204b7abd095df8c.png" alt="pandora"></div><div class="col-12 col-lg-8 my-auto"><p class="text-center text-lg-left title-text text-capitalize"><span>Internal Talk</span> to ML Team, Applying Computational Linguistics to Music Theory Analysis</p></div></div><div class="row"><div class="col-12 col-lg-4 mb-5 mb-lg-0 d-flex justify-content-center justify-content-lg-start"><img class="image-fluid" src="img/amazon.075f35aa700fae7609b15d98a7a4c49d.png" alt="amazon"></div><div class="col-12 col-lg-8 my-auto"><p class="text-center text-lg-left title-text text-capitalize"><span>Internal Talk</span> to ML Team, Computational Music Theory with Probabilistic Grammars</p></div></div><div class="row"><div class="col-12 col-lg-4 mb-5 mb-lg-0 d-flex justify-content-center justify-content-lg-start"><img class="image-fluid" src="img/music-gaming.563de44b9b6d0e119cd67438cb3875c0.png" alt="music-gaming-con"></div><div class="col-12 col-lg-8 my-auto"><p class="text-center text-lg-left title-text text-capitalize"><span>Participant</span>, Sync Panel (2020)</p></div></div></div></section><footer><div class="container"><div class="row"><div class="col-12 text-center"><div class="d-flex justify-content-center"><a href="https://twitter.com/ryangrovesmusic/" target="_blank" rel="noopener noreferrer"><img src="img/twitter.f5befa4a75fcc7cdd347fa80400fe6e8.svg" alt="Twitter Logo" class="social-media-icon twitter-icon"> </a><a href="https://www.linkedin.com/in/ryan-groves/" target="_blank" rel="noopener noreferrer"><img src="img/linkedin.111c8c5a3f2678f167b71373335af9b5.svg" alt="LinkedIn logo" class="social-media-icon"></a></div><p>Copyright © Ryan Groves 2020</p></div></div></div></footer><div class="modal-backdrop d-none fade" id="backdrop"></div><div class="modal fade d-none" id="video-modal" tabindex="-1" role="dialog" aria-hidden="true"><div class="modal-dialog" role="document"><div class="modal-content"><div class="modal-header"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true"><img src="img/close.d6a652bbcab20190b2bce9eb2b5811f6.svg" alt="Close"></span></button></div><div class="modal-body"><div class="container-fluid"><div class="row d-flex justify-content-center"><div class="col-12"><div class="embed-responsive embed-responsive-16by9"><iframe class="embed-responsive-item" src="" id="video" allow="autoplay"></iframe></div></div></div></div></div></div></div></div><script src="./js/common.9fb2d41a0cbf2bf572c4.js"></script><script src="./js/speaking.9fb2d41a0cbf2bf572c4.js"></script></body></html>